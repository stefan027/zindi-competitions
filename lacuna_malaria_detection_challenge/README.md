
# Lacuna Malaria Detection Challenge

## Solution overview
The solutions consists of five elements briefly outlined below. Refer to the `Running the model` section below for more details.
 1. A binary image classifier to distinguish between images with malaria and the `NEG` class
 2. Train a `DDQ` image detection model using the `MMDetection` library
 3. Train a `DINO` image detection model using the `MMDetection` library
 4. Train a `RT-DETR` image detection model using the `ultralytics` library
 5. Combine the predictions from the three image detectors to generate the final predictions.

## Installation
The required Python packages can be installed using the steps below. Alternatively, the depenencies can be install directly in the Jupyter notebooks.

>Make sure you are in the base folder when installing `MMDetection` (i.e., the same folder where `requirements.txt`, `Train.csv`, `Test.csv`, the Jupyter notebooks, and the images are; see `Setting up the folders` below for more details.)

1. Install required Python packages:
```bash
pip install -q -r requirements.txt --index-url https://download.pytorch.org/whl/cu121
```

2. Install OpenMIM, MMEngine and MMCV:
```bash
pip install -U openmim
mim install mmengine
mim install "mmcv>=2.0.0rc4, <2.2.0"
```

3. Install MMDetection:
```bash
git clone https://github.com/open-mmlab/mmdetection.git
cd mmdetection && pip install -e .
```

# Running the model

## Setting up the folders
Before running the notebooks, make sure that all five notebooks are in the same folder as the `Train.csv`, `Test.csv`, and `SampleSubmission.csv` files. The images must also be in the folder. The images can either be a single zip file called `images.zip`, or extracted into a subfolder called `images`.

    Base directory
    - images.zip
    - Train.csv
    - Test.csv
    - SampleSubmission.csv
    - requirements.txt
    - 00_classifier.ipynb
    - 01_malaria_detection_dino_1cycle.ipynb
    - 02_malaria_detection_ddq_1cycle.ipynb
    - 03_malaria_detection_rtdetr.ipynb
    - 04_fuse_predictions.ipynb

**OR**

    Base directory
    - images/
        - 12345.jpg
        - 34567.jpg
        - etc.
    - Train.csv
    - Test.csv
    - SampleSubmission.csv
    - requirements.txt
    - 00_classifier.ipynb
    - 01_malaria_detection_dino_1cycle.ipynb
    - 02_malaria_detection_ddq_1cycle.ipynb
    - 03_malaria_detection_rtdetr.ipynb
    - 04_fuse_predictions.ipynb

## Running the notebooks
The five notebooks must be run in order, i.e.:
  - `00_classifier.ipynb`
  - `01_malaria_detection_dino_1cycle.ipynb`
  - `02_malaria_detection_ddq_1cycle.ipynb`
  - `03_malaria_detection_rtdetr.ipynb`
  - `04_fuse_predictions.ipynb`

Each notebook performs training and inference. Each notebook saves a `.csv` output file in the base directory. These output files are used in subsequent steps. If working on a platform that doesn't provide persistent storage, make sure to copy the output files to persistent storage and to upload them to the base directory for subsequent steps. The name of the output file produced by each notebook is given in the table below.

| Notebook name                           | Output file       |
| ----------------------------------------| ------------------|
| 00_classifier.ipynb                     | df_pred_cls.csv |
| 01_malaria_detection_dino_1cycle.ipynb  | submission_dino_swin_1cycle_epoch15.csv |
| 02_malaria_detection_ddq_1cycle.ipynb   | submission_ddq_swin_1cycle_epoch18.csv |
| 03_malaria_detection_rtdetr.ipynb       | submission_rtdetr.csv |
| 04_fuse_predictions.ipynb               | submission_fused.csv |

>The file submission file, generated by `04_fuse_predictions.ipynb`, is called `submission_fused.csv`.

## Hardware specifications
The model was trained on [Paperspace Notebooks](https://www.paperspace.com/notebooks) and [Jarvis Labs](https://jarvislabs.ai/) on a single NVIDIA A6000 GPU with 48GB of GPU memory. The A6000 was chosen since it is almost 40% cheaper than an A100 (40GB) on both platforms. The code also runs on a A100, although an occasional CUDA OOM error (that I cannot explain but did not investigate in detail) occurs when training the `DINO` and `DDQ` models. Reducing the batch size from 2 to 1 removes that problem and produces similar results. It was also found that simply resuming training usually works as well.

Approximate running time per notebook on a A6000 instance is given in the table below (similar for A100). In all cases, the bulk of the run time is for training. Inference takes less than 10 minutes per notebook, and no more than 30 minutes combined.

| Notebook name                           | Approximate run time |
| ----------------------------------------| --------------------:|
| 00_classifier.ipynb                     |  10 min       |
| 01_malaria_detection_dino_1cycle.ipynb  |  7.5 hrs      |
| 02_malaria_detection_ddq_1cycle.ipynb   |  6 hrs        |
| 03_malaria_detection_rtdetr.ipynb       |  1.25 hrs     |
| 04_fuse_predictions.ipynb               |  10 min       |
| **Total (setup + train + inference)**   |  **< 16 hrs** |

## Post-processing trick

Examining the training images by size, we see four different image sizes. It appears as if the dataset was possibly constructed from four different sources, and that each source was perhaps labeled slighthly differently. Notably, we see:

 - All images with size (4000, 3000) are `NEG`. If all these images came from the same source (with, e.g., similar lighting) it probably explains why the classifier was able to classify `NEG`s so accurately. For competition purposes, this information could have been directly exploited to determine `NEG`s, but I decided to still use a ML classifier since that's the correct 'real-world' approach, and the classifier is 100% accurate anyway.
 - `WBC`s are not labeled in images of size (4160, 3120). A LB boost could be achieved by removing all `WBC` predictions for images of size (4160, 3120). I didn't exploit this in my submission but I'm curious if other competitors found and utilised this 'trick'.

 ```python
 df_trn = pd.read_csv("Train.csv")
trn_img_ids = list(df_trn["Image_ID"].drop_duplicates())
df_sz = []
for img_id in trn_img_ids:
    h, w = Image.open(f"images/{img_id}").size
    df_sz.append([img_id, h, w])
df_sz = pd.DataFrame(df_sz, columns=["Image_ID", "height", "width"])

df_trn.groupby(["height", "width", "class"]).agg({"Image_ID": "nunique"})
```
>Output
 			
|height | width | class       | count |
|-------| ------|-------------|------:|
| 1920  | 1080  | Trophozoite |   909 |
|       |       | WBC         |   897 |
| 4000  | 3000  | NEG         |   688 |
| 4032  | 3016  | Trophozoite |   769 |
|       |       | WBC         |   686 |
|4160   | 3120  | Trophozoite |   340 |
